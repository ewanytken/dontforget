{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Создаем входной массив из двух изображений RGB 3*3\n",
    "input_images = torch.tensor(\n",
    "      [[[[0,  1,  2],\n",
    "         [3,  4,  5],\n",
    "         [6,  7,  8]],\n",
    "\n",
    "        [[9, 10, 11],\n",
    "         [12, 13, 14],\n",
    "         [15, 16, 17]],\n",
    "\n",
    "        [[18, 19, 20],\n",
    "         [21, 22, 23],\n",
    "         [24, 25, 26]]],\n",
    "\n",
    "\n",
    "       [[[27, 28, 29],\n",
    "         [30, 31, 32],\n",
    "         [33, 34, 35]],\n",
    "\n",
    "        [[36, 37, 38],\n",
    "         [39, 40, 41],\n",
    "         [42, 43, 44]],\n",
    "\n",
    "        [[45, 46, 47],\n",
    "         [48, 49, 50],\n",
    "         [51, 52, 53]]  ]     ])\n",
    "\n",
    "\n",
    "def get_padding2d(input_images):\n",
    "    \n",
    "    padded_images = torch.zeros(2,3,5,5)\n",
    "    for z in range(0,2): \n",
    "        for i in range(0,3):\n",
    "            for j  in range(0,3):\n",
    "                for k in  range(0,3):\n",
    "                    padded_images[z][i][j+1][k+1] = input_images[z][i][j][k]\n",
    "    \n",
    "#     padded_images = # добавить нулей с четырех сторон каждого изображения\n",
    "    return padded_images\n",
    "\n",
    "\n",
    "correct_padded_images = torch.tensor(\n",
    "       [[[[0.,  0.,  0.,  0.,  0.],\n",
    "          [0.,  0.,  1.,  2.,  0.],\n",
    "          [0.,  3.,  4.,  5.,  0.],\n",
    "          [0.,  6.,  7.,  8.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0.,  9., 10., 11.,  0.],\n",
    "          [0., 12., 13., 14.,  0.],\n",
    "          [0., 15., 16., 17.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 18., 19., 20.,  0.],\n",
    "          [0., 21., 22., 23.,  0.],\n",
    "          [0., 24., 25., 26.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]]],\n",
    "\n",
    "\n",
    "        [[[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 27., 28., 29.,  0.],\n",
    "          [0., 30., 31., 32.,  0.],\n",
    "          [0., 33., 34., 35.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 36., 37., 38.,  0.],\n",
    "          [0., 39., 40., 41.,  0.],\n",
    "          [0., 42., 43., 44.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 45., 46., 47.,  0.],\n",
    "          [0., 48., 49., 50.,  0.],\n",
    "          [0., 51., 52., 53.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]]]])\n",
    "\n",
    "# Проверка происходит автоматически вызовом следующего кода\n",
    "# (раскомментируйте для самостоятельной проверки,\n",
    "#  в коде для сдачи задания должно быть закомментировано):\n",
    "print(torch.allclose(get_padding2d(input_images), correct_padded_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(\n",
    "      [[[[0,  1,  2],\n",
    "         [3,  4,  5],\n",
    "         [6,  7,  8]],\n",
    "\n",
    "        [[9, 10, 11],\n",
    "         [12, 13, 14],\n",
    "         [15, 16, 17]],\n",
    "\n",
    "        [[18, 19, 20],\n",
    "         [21, 22, 23],\n",
    "         [24, 25, 26]]],\n",
    "\n",
    "\n",
    "       [[[27, 28, 29],\n",
    "         [30, 31, 32],\n",
    "         [33, 34, 35]],\n",
    "\n",
    "        [[36, 37, 38],\n",
    "         [39, 40, 41],\n",
    "         [42, 43, 44]],\n",
    "\n",
    "        [[45, 46, 47],\n",
    "         [48, 49, 50],\n",
    "         [51, 52, 53]]  ]     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(2,3,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  1.,  2.,  0.],\n",
       "          [ 0.,  3.,  4.,  5.,  0.],\n",
       "          [ 0.,  6.,  7.,  8.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  9., 10., 11.,  0.],\n",
       "          [ 0., 12., 13., 14.,  0.],\n",
       "          [ 0., 15., 16., 17.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0., 18., 19., 20.,  0.],\n",
       "          [ 0., 21., 22., 23.,  0.],\n",
       "          [ 0., 24., 25., 26.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0., 27., 28., 29.,  0.],\n",
       "          [ 0., 30., 31., 32.,  0.],\n",
       "          [ 0., 33., 34., 35.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0., 36., 37., 38.,  0.],\n",
       "          [ 0., 39., 40., 41.,  0.],\n",
       "          [ 0., 42., 43., 44.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0., 45., 46., 47.,  0.],\n",
       "          [ 0., 48., 49., 50.,  0.],\n",
       "          [ 0., 51., 52., 53.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for z in range(0,2): \n",
    "    for i in range(0,3):\n",
    "        for j  in range(0,3):\n",
    "            for k in  range(0,3):\n",
    "                y[z][i][j+1][k+1] = x[z][i][j][k]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 5, 5)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0], x.shape[1], x.shape[2] + 2, x.shape[3] + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 10  8  8]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_out_shape(input_matrix_shape, out_channels, kernel_size, stride, padding):\n",
    "    x = np.fix((input_matrix_shape[2]+2*padding - kernel_size)/ stride +1)\n",
    "    y = np.fix((input_matrix_shape[3]+2*padding - kernel_size)/ stride +1)\n",
    "    out_shape = np.int_([input_matrix_shape[0], out_channels, x, y])\n",
    "    \n",
    "    print(out_shape)\n",
    "    return out_shape\n",
    "    \n",
    "print(np.array_equal(\n",
    "    calc_out_shape(input_matrix_shape=[2, 3, 10, 10],\n",
    "                   out_channels=10,\n",
    "                   kernel_size=3,\n",
    "                   stride=1,\n",
    "                   padding=0),\n",
    "    [2, 10, 8, 8]))\n",
    "\n",
    "# ... и ещё несколько подобных кейсов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693147\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_array(s):\n",
    "    return np.array([int(s.strip()) for s in s.strip().split(' ')])\n",
    "\n",
    "def read_array():\n",
    "    return parse_array(sys.stdin.readline())\n",
    "\n",
    "def calculate_pmi(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.log((np.count_nonzero((a == 1) & (b == 1)) / a.size) / ((np.count_nonzero(a == 1) / a.size) * (np.count_nonzero(b == 1) / b.size)))\n",
    "    \n",
    "a = [1, 0, 0, 1, 1, 0]\n",
    "b = [1, 0, 0, 0, 1, 0]\n",
    "pmi_value = calculate_pmi(a, b)\n",
    "\n",
    "print('{:.6f}'.format(pmi_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6439335666815615"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1/x**2 for x in range(1,1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "абв123 - ТЕСТ ПРОЙДЕН\n",
      "123абв - ТЕСТ ПРОЙДЕН\n",
      "-123абв - ТЕСТ ПРОЙДЕН\n",
      "123.23 - ТЕСТ ПРОЙДЕН\n",
      "123,23 - ТЕСТ ПРОЙДЕН\n",
      "Мама мыла -56.035 раму. - ТЕСТ ПРОЙДЕН\n",
      "Мама мыла -56,035 раму. - ТЕСТ ПРОЙДЕН\n",
      "Мама мыла -.035 раму. - ТЕСТ ПРОЙДЕН\n",
      "Мама мыла -,035 раму. - ТЕСТ ПРОЙДЕН\n",
      "Мама (ну та самая) мыла раму! - ТЕСТ ПРОЙДЕН\n",
      "Мама мыла раму. - ТЕСТ ПРОЙДЕН\n",
      "Мама_мыла_раму. - ТЕСТ ПРОЙДЕН\n",
      "Это мама, которая    мыла раму 3раза? Да, всё-таки это - она! Офигеть... - ТЕСТ ПРОЙДЕН\n",
      "вот такая дробь .52 - ТЕСТ ПРОЙДЕН\n",
      "и вот такая дробь -.52 - ТЕСТ ПРОЙДЕН\n",
      "Согласно ст.89 §§ 22-24 и 27 следует... - ТЕСТ ПРОЙДЕН\n",
      "вот такая дробь 0.52 - ТЕСТ ПРОЙДЕН\n",
      "а это вроде и не дробь 25. - ТЕСТ ПРОЙДЕН\n",
      "абв абв123 123 .123 -.123 -.123/123 123/1234 -123/1234 1.123 -1.123 123. -123. ..... ,,,,, - ТЕСТ ПРОЙДЕН\n",
      "Список:\n",
      "    1. Пункт №1* (со звёздочкой) ;\n",
      "    2. Пункт второй [#2] 2 < 3 & 2 > 1;\n",
      "    3.Пункт третий {и последний} - ТЕСТ ПРОЙДЕН\n",
      " - ТЕСТ ПРОЙДЕН\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "TOKENIZE_RE = re.compile(r'[А-ЯЁа-яё]+|-?\\d*[.,]?\\d+|\\S', re.I)\n",
    "\n",
    "tests = {\n",
    "    'абв123': ['абв', '123'],\n",
    "    '123абв': ['123', 'абв'],\n",
    "    '-123абв': ['-123', 'абв'],\n",
    "    '123.23': ['123.23'],\n",
    "    '123,23': ['123,23'],\n",
    "    'Мама мыла -56.035 раму.': ['мама', 'мыла', '-56.035', 'раму', '.'],\n",
    "    'Мама мыла -56,035 раму.': ['мама', 'мыла', '-56,035', 'раму', '.'],\n",
    "    'Мама мыла -.035 раму.': ['мама', 'мыла', '-.035', 'раму', '.'],\n",
    "    'Мама мыла -,035 раму.': ['мама', 'мыла', '-,035', 'раму', '.'],\n",
    "    'Мама (ну та самая) мыла раму!': ['мама', '(', 'ну', 'та', 'самая', ')', 'мыла', 'раму', '!'],\n",
    "    'Мама мыла раму.': ['мама', 'мыла', 'раму', '.'],\n",
    "    'Мама_мыла_раму.': ['мама', '_', 'мыла', '_', 'раму', '.'],\n",
    "    'Это мама, которая    мыла раму 3раза? Да, всё-таки это - она! Офигеть...': ['это', 'мама', ',', 'которая', 'мыла', 'раму', '3', 'раза', '?', 'да', ',', 'всё', '-', 'таки', 'это', '-', 'она', '!', 'офигеть', '.', '.', '.'],\n",
    "    'вот такая дробь .52': ['вот', 'такая', 'дробь', '.52'],\n",
    "    'и вот такая дробь -.52': ['и', 'вот', 'такая', 'дробь', '-.52'],\n",
    "    'Согласно ст.89 §§ 22-24 и 27 следует...': ['согласно', 'ст', '.89', '§', '§', '22', '-24', 'и', '27', 'следует', '.', '.', '.'],\n",
    "    'вот такая дробь 0.52': ['вот', 'такая', 'дробь', '0.52'],\n",
    "    'а это вроде и не дробь 25.': ['а', 'это', 'вроде', 'и', 'не', 'дробь', '25', '.'],          \n",
    "    'абв абв123 123 .123 -.123 -.123/123 123/1234 -123/1234 1.123 -1.123 123. -123. ..... ,,,,,': \\\n",
    "    ['абв', 'абв', '123', '123', '.123', '-.123', '-.123', '/', '123', \n",
    "     '123', '/', '1234', '-123', '/', '1234', '1.123', '-1.123', '123', \n",
    "     '.', '-123', '.', '.', '.', '.', '.', '.', ',', ',', ',', ',', ','],\n",
    "    \"\"\"Список:\n",
    "    1. Пункт №1* (со звёздочкой) ;\n",
    "    2. Пункт второй [#2] 2 < 3 & 2 > 1;\n",
    "    3.Пункт третий {и последний}\"\"\": \\\n",
    "    ['список', ':', '1', '.', 'пункт', '№', '1', '*', '(', 'со', 'звёздочкой',\n",
    "     ')', ';', '2', '.', 'пункт', 'второй', '[', '#', '2', ']', '2', '<', '3',\n",
    "     '&', '2', '>', '1', ';', '3', '.', 'пункт', 'третий', '{', 'и', 'последний', '}'],\n",
    "#     'везучий случай': ['везучии', '̆', 'случай'],\n",
    "    '': []\n",
    "}\n",
    "\n",
    "def tokenize(txt):\n",
    "    return TOKENIZE_RE.findall(txt)\n",
    "\n",
    "\n",
    "for test in tests:\n",
    "    tokens = tokenize(test.strip().lower())\n",
    "    try:\n",
    "        assert tokens == tests[test]\n",
    "        print(f'{test} - ТЕСТ ПРОЙДЕН')\n",
    "    except AssertionError:\n",
    "        print(f'{test} - ТЕСТ ПРОВАЛЕН')\n",
    "        print('Ожидается:')\n",
    "        print(tests[test])\n",
    "        print('Получено:')\n",
    "        print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'v'}\n"
     ]
    }
   ],
   "source": [
    "s = set('a')\n",
    "s = set('v')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['казнить', 'нельзя', 'помиловать', 'нельзя', 'освободить']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'Казнить нельзя, помиловать. Нельзя наказывать.',\n",
    "    'Казнить, нельзя помиловать. Нельзя освободить.',\n",
    "    'Нельзя не помиловать.',\n",
    "    'Обязательно освободить.']\n",
    "reg = re.compile(r'[А-ЯЁа-яё]+', re.I)\n",
    "reg.findall(texts[1].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "def corpus2token(texts):\n",
    "    \n",
    "    dictText = collections.defaultdict(int)\n",
    "    freqDict = collections.defaultdict(int)\n",
    "\n",
    "    reg = re.compile(r'[А-ЯЁа-яё]+', re.I)\n",
    "    count_freq = 0\n",
    "    \n",
    "    for text in texts:\n",
    "        text = reg.findall(text.lower())\n",
    "        unique_text = set(text)\n",
    "        for token in text:\n",
    "            dictText[token] += 1\n",
    "        for utoken in unique_text:\n",
    "            freqDict[utoken] += 1\n",
    "    dictText = sorted(dictText.items(),reverse=True, key=lambda x: x[1])\n",
    "\n",
    "    freqDict = sorted(freqDict.items(), reverse=True, key=lambda x: x[1])\n",
    "    freqDict = {word : freq / len(texts) for (word, freq) in freqDict}\n",
    "    \n",
    "    return dictText, freqDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('нельзя', 5), ('помиловать', 3), ('казнить', 2), ('освободить', 2), ('наказывать', 1), ('не', 1), ('обязательно', 1)]\n",
      "{'помиловать': 0.75, 'нельзя': 0.75, 'казнить': 0.5, 'освободить': 0.5, 'наказывать': 0.25, 'не': 0.25, 'обязательно': 0.25}\n"
     ]
    }
   ],
   "source": [
    "d, f = corpus2token(texts)\n",
    "print(d)\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2id {'наказывать': 0, 'не': 1, 'обязательно': 2, 'казнить': 3, 'освободить': 4, 'нельзя': 5, 'помиловать': 6}\n",
      "7\n",
      "word2freq [0.25 0.25 0.25 0.5  0.5  0.75 0.75]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5cf76553e0b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word2freq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2freq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdok_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokens'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'Казнить нельзя, помиловать. Нельзя наказывать.',\n",
    "    'Казнить, нельзя помиловать. Нельзя освободить.',\n",
    "    'Нельзя не помиловать.',\n",
    "    'Обязательно освободить.']\n",
    "\n",
    "\n",
    "word_counts = collections.defaultdict(int)\n",
    "doc_n = 0\n",
    "reg = re.compile(r'[А-ЯЁа-яё]+', re.I)\n",
    "\n",
    "def tokenize_text_simple_regex(txt):\n",
    "    txt = txt.lower()\n",
    "    all_tokens = reg.findall(txt)\n",
    "    return all_tokens\n",
    "\n",
    "def tokenize_corpus(texts, tokenizer=tokenize_text_simple_regex):\n",
    "    return [tokenizer(text) for text in texts]\n",
    "tokens = tokenize_corpus(corpus)\n",
    "\n",
    "for txt in corpus:\n",
    "    doc_n += 1\n",
    "    txt = reg.findall(txt.lower())\n",
    "    unique_text_tokens = set(txt)\n",
    "    for token in unique_text_tokens:\n",
    "        word_counts[token] += 1\n",
    "\n",
    "sorted_word_counts = sorted(word_counts.items(),\n",
    "                           key=lambda x:(x[1],x[0]))\n",
    "\n",
    "word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
    "word2freq = np.array([cnt/doc_n for _, cnt in sorted_word_counts], dtype='float32')\n",
    "print('word2id', word2id)\n",
    "print(len(word2id))\n",
    "print('word2freq', word2freq)\n",
    "\n",
    "result = scipy.sparse.dok_matrix((len(tokens), len(word2id)), dtype='float32')\n",
    "print('result', len(result))\n",
    "print('tokens',len( tokens))\n",
    "for text_i, text in enumerate(tokens):\n",
    "    print(text)\n",
    "    for token in text:\n",
    "        if token in word2id:\n",
    "            result[text_i, word2id[token]] += 1\n",
    "            print('token, text_i, word2id[token], result[text_i, word2id[token]]', token, text_i, word2id[token], result[text_i, word2id[token]])\n",
    "\n",
    "print(result)\n",
    "result = result.multiply(1 / result.sum(1))\n",
    "\n",
    "result1 = (result > 0).astype('float32').multiply(1 / word2freq)\n",
    "\n",
    "print('result2onedividesum', result)\n",
    "print('result2wordfreq', result1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7292864\n",
      "[[0.1823216  0.28768212 0.4054651  0.1823216  0.29389334 0.32020885\n",
      "  0.21744177]]\n",
      "[[0.45583245 0.4063126  0.32467166 0.45583245 0.4027003  0.3865399\n",
      "  0.44179267]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'tocsr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-9eeff195d131>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdok_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;31m# print(s[:, 4], ms[0,1], std[0,2])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36mpower\u001b[1;34m(self, n, dtype)\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;34m\"\"\"Element-wise power.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'tocsr'"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "corpus = [\n",
    "    'Казнить нельзя, помиловать. Нельзя наказывать.',\n",
    "    'Казнить, нельзя помиловать. Нельзя освободить.',\n",
    "    'Нельзя не помиловать.',\n",
    "    'Обязательно освободить.']\n",
    "\n",
    "\n",
    "word_counts = collections.defaultdict(int)\n",
    "doc_n = 0\n",
    "reg = re.compile(r'[А-ЯЁа-яё]+', re.I)\n",
    "\n",
    "def tokenize_text_simple_regex(txt):\n",
    "    txt = txt.lower()\n",
    "    all_tokens = reg.findall(txt)\n",
    "    return all_tokens\n",
    "\n",
    "def tokenize_corpus(texts, tokenizer=tokenize_text_simple_regex):\n",
    "    return [tokenizer(text) for text in texts]\n",
    "tokens = tokenize_corpus(corpus)\n",
    "\n",
    "for txt in corpus:\n",
    "    doc_n += 1\n",
    "    txt = reg.findall(txt.lower())\n",
    "    unique_text_tokens = set(txt)\n",
    "    for token in unique_text_tokens:\n",
    "        word_counts[token] += 1\n",
    "\n",
    "sorted_word_counts = sorted(word_counts.items(),\n",
    "                           key=lambda x:(x[1],x[0]))\n",
    "\n",
    "word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
    "word2freq = np.array([cnt/doc_n for _, cnt in sorted_word_counts], dtype='float32')\n",
    "result = scipy.sparse.dok_matrix((len(tokens), len(word2id)), dtype='float32')\n",
    "\n",
    "for text_i, text in enumerate(tokens):\n",
    "    for token in text:\n",
    "        if token in word2id:\n",
    "            result[text_i, word2id[token]] += 1\n",
    "            \n",
    "from scipy.linalg import logm\n",
    "\n",
    "s = result.multiply(1 / result.sum(1))\n",
    "s.data = s.data + 1\n",
    "s.data = np.log(s.data)\n",
    "s = s.multiply(1/word2freq).tocsr()\n",
    "print(s[0,0])\n",
    "ms = s.mean(axis=0)\n",
    "print(ms)\n",
    "sq = s\n",
    "sqr = np.square(sq.data)\n",
    "# a[a.nonzero()] = a[a.nonzero()] + 1\n",
    "std = sqr.mean(axis=0) - np.square(ms)\n",
    "print(std)\n",
    "for i in range(s.get_shape()[1]):\n",
    "    s[:,i] = (s[:,i]).multiply(scipy.sparse.dok_matrix.power(-1,std[0,i])) \n",
    "# print(s[:, 4], ms[0,1], std[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "  (1, 1)\t2.0\n",
      "  (1, 2)\t3.0\n",
      "  (2, 1)\t3.0\n",
      "  (2, 2)\t4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import dok_matrix\n",
    "S = dok_matrix((3, 3), dtype=np.float32)\n",
    "for i in range(1, 3, 1):\n",
    "    for j in range(1, 3, 1):\n",
    "        S[i, j] = i + j    # Update element\n",
    "print(S)\n",
    "# S = S.multiply(1 / S.sum(0))\n",
    "# print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 5. 7.]]\n",
      "[[0.]\n",
      " [5.]\n",
      " [7.]]\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "print(S.sum(0))\n",
    "print(S.sum(1))\n",
    "print(S.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t3\n",
      "  (0, 2)\t1\n",
      "  (1, 1)\t2\n",
      "  (3, 3)\t1\n",
      "[[3 0 1 0 0 0 0]\n",
      " [0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "[[3 0 1 0 0 0 0]\n",
      " [0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from scipy.sparse import coo_matrix\n",
    "row  = array([0, 0, 1, 3, 1, 0, 0])\n",
    "col  = array([0, 2, 1, 3, 1, 0, 0])\n",
    "data = array([1, 1, 1, 1, 1, 1, 1])\n",
    "A = coo_matrix((data, (row, col)), shape=(7, 7)).tocsr()\n",
    "A.toarray()\n",
    "print(A)\n",
    "print(A.toarray())\n",
    "print(A.tocsr().toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from scipy.sparse import coo_matrix\n",
    "row  = array([0, 0, 1, 3, 1, 0, 0])\n",
    "col  = array([0, 2, 1, 3, 1, 0, 0])\n",
    "data = array([1, 1, 1, 1, 1, 1, 1])\n",
    "A = coo_matrix((data, (row, col)), shape=(4, 4)).tocsc()\n",
    "A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t2\n",
      "  (1, 0)\t1\n",
      "  (0, 1)\t3\n",
      "  (1, 0)\t2\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "a = csr_matrix([[0, 2, 0], [1, 0, 0]])\n",
    "print(a)\n",
    "\n",
    "a[a.nonzero()] = a[a.nonzero()] + 1\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3], [5, 5], [6, 1]]\n"
     ]
    }
   ],
   "source": [
    "lists = [[2,5,6],[3,5,1]]\n",
    "result = [[ j[i] for j in lists ] for i in range(3)]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 5, 1],\n",
       "       [0, 0, 0],\n",
       "       [5, 0, 1],\n",
       "       [5, 1, 0],\n",
       "       [5, 0, 1],\n",
       "       [5, 1, 0],\n",
       "       [0, 5, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 3, 1],\n",
       "       [0, 0, 0],\n",
       "       [3, 0, 1],\n",
       "       [3, 0, 0],\n",
       "       [3, 5, 1],\n",
       "       [3, 1, 0],\n",
       "       [5, 3, 1],\n",
       "       [5, 0, 0],\n",
       "       [5, 5, 1],\n",
       "       [5, 1, 0],\n",
       "       [5, 5, 1],\n",
       "       [5, 0, 0],\n",
       "       [5, 3, 1],\n",
       "       [5, 0, 0],\n",
       "       [3, 5, 1],\n",
       "       [3, 0, 0],\n",
       "       [3, 0, 1],\n",
       "       [3, 0, 0],\n",
       "       [0, 3, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 5, 1],\n",
       "       [0, 0, 0],\n",
       "       [5, 0, 1],\n",
       "       [5, 0, 0],\n",
       "       [5, 0, 1],\n",
       "       [5, 0, 0],\n",
       "       [0, 5, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 5, 1],\n",
       "       [0, 0, 0],\n",
       "       [5, 0, 1],\n",
       "       [5, 1, 0],\n",
       "       [5, 2, 1],\n",
       "       [5, 0, 0],\n",
       "       [2, 5, 1],\n",
       "       [2, 1, 0],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 0],\n",
       "       [0, 2, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0],\n",
       "       [1, 3, 1],\n",
       "       [1, 0, 0],\n",
       "       [3, 1, 1],\n",
       "       [3, 1, 0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "text = [1, 0, 1, 0, 0, 5, 0, 3, 5, 5, 3, 0, 5, 0, 5, 2, 0, 1, 3]\n",
    "window_size = 3\n",
    "vocab_size = 6\n",
    "ns_rate = 1\n",
    "temp = []\n",
    "for i in range(0, len(text)):\n",
    "    for j in range(1, window_size//2+1):\n",
    "        if ((i-j) >= 0):\n",
    "            temp.append([text[i], text[i-j], 1])\n",
    "            for m in range(0, ns_rate):\n",
    "                temp.append([text[i], text[np.random.randint(0, vocab_size-1)], 0])\n",
    "        if ((i+j) < len(text)):\n",
    "            temp.append([text[i], text[i+j], 1])\n",
    "            for m in range(0, ns_rate):\n",
    "                temp.append([text[i], text[np.random.randint(0, vocab_size-1)], 0])\n",
    "            \n",
    "s = np.array(temp)\n",
    "print(s.shape)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 0, 1], [1, 2, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1], [0, 2, 0], [1, 0, 1], [1, 3, 0], [1, 0, 1], [1, 2, 0], [0, 1, 1], [0, 1, 0], [0, 0, 1], [0, 3, 0], [0, 0, 1], [0, 2, 0], [0, 5, 1], [0, 2, 0], [5, 0, 1], [5, 2, 0], [5, 0, 1], [5, 0, 0], [0, 5, 1], [0, 4, 0], [0, 3, 1], [0, 1, 0], [3, 0, 1], [3, 0, 0], [3, 5, 1], [3, 2, 0], [5, 3, 1], [5, 1, 0], [5, 5, 1], [5, 4, 0], [5, 5, 1], [5, 2, 0], [5, 3, 1], [5, 0, 0], [3, 5, 1], [3, 0, 0], [3, 0, 1], [3, 5, 0], [0, 3, 1], [0, 2, 0], [0, 5, 1], [0, 1, 0], [5, 0, 1], [5, 2, 0], [5, 0, 1], [5, 2, 0], [0, 5, 1], [0, 3, 0], [0, 5, 1], [0, 1, 0], [5, 0, 1], [5, 1, 0], [5, 2, 1], [5, 2, 0], [2, 5, 1], [2, 3, 0], [2, 0, 1], [2, 5, 0], [0, 2, 1], [0, 2, 0], [0, 1, 1], [0, 3, 0], [1, 0, 1], [1, 2, 0], [1, 3, 1], [1, 0, 0], [3, 1, 1], [3, 4, 0]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "[[1, 0, 1], [1, 2, 0], [1, 3, 0], [0, 1, 1], [0, 0, 0], [0, 1, 0], [0, 1, 1], [0, 2, 0], [0, 3, 0], [1, 0, 1], [1, 2, 0], [1, 3, 0], [1, 0, 1], [1, 3, 0], [1, 0, 0], [0, 1, 1], [0, 2, 0], [0, 2, 0], [0, 0, 1], [0, 2, 0], [0, 3, 0], [0, 0, 1], [0, 4, 0], [0, 1, 0], [0, 5, 1], [0, 1, 0], [0, 3, 0], [5, 0, 1], [5, 2, 0], [5, 0, 0], [5, 0, 1], [5, 1, 0], [5, 1, 0], [0, 5, 1], [0, 0, 0], [0, 0, 0], [0, 3, 1], [0, 0, 0], [0, 4, 0], [3, 0, 1], [3, 1, 0], [3, 1, 0], [3, 5, 1], [3, 0, 0], [3, 2, 0], [5, 3, 1], [5, 2, 0], [5, 4, 0], [5, 5, 1], [5, 0, 0], [5, 2, 0], [5, 5, 1], [5, 1, 0], [5, 2, 0], [5, 3, 1], [5, 3, 0], [5, 2, 0], [3, 5, 1], [3, 1, 0], [3, 1, 0], [3, 0, 1], [3, 2, 0], [3, 0, 0], [0, 3, 1], [0, 4, 0], [0, 2, 0], [0, 5, 1], [0, 0, 0], [0, 1, 0], [5, 0, 1], [5, 1, 0], [5, 3, 0], [5, 0, 1], [5, 0, 0], [5, 0, 0], [0, 5, 1], [0, 2, 0], [0, 0, 0], [0, 5, 1], [0, 2, 0], [0, 1, 0], [5, 0, 1], [5, 1, 0], [5, 1, 0], [5, 2, 1], [5, 2, 0], [5, 3, 0], [2, 5, 1], [2, 0, 0], [2, 0, 0], [2, 0, 1], [2, 0, 0], [2, 4, 0], [0, 2, 1], [0, 0, 0], [0, 4, 0], [0, 1, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 0], [1, 4, 0], [1, 3, 1], [1, 3, 0], [1, 2, 0], [3, 1, 1], [3, 4, 0], [3, 4, 0]]\n"
     ]
    }
   ],
   "source": [
    "text = [1, 0, 1, 0, 0, 5, 0, 3, 5, 5, 3, 0, 5, 0, 5, 2, 0, 1, 3]\n",
    "print(len(text))\n",
    "window_size = 3\n",
    "vocab_size = 6\n",
    "ns_rate = 2\n",
    "\n",
    "def generate_w2v_sgns_samples(text, window_size, vocab_size, ns_rate):\n",
    "    temp = []\n",
    "    for i in range(0, len(text)):\n",
    "        for j in range(1, window_size//2+1):\n",
    "            if ((i-j) >= 0):\n",
    "                temp.append([text[i], text[i-j], 1])\n",
    "                for m in range(0, ns_rate):\n",
    "                    temp.append([text[i], np.random.randint(0, vocab_size-1), 0])\n",
    "            if ((i+j) < len(text)):\n",
    "                temp.append([text[i], text[i+j], 1])\n",
    "                for m in range(0, ns_rate):\n",
    "                    temp.append([text[i], np.random.randint(0, vocab_size-1), 0])\n",
    "    return temp\n",
    "\n",
    "print(generate_w2v_sgns_samples(text, window_size, vocab_size, ns_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-eb1086c4c89d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcenter_embeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcenter_word\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_embeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcontext_word\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mupdate_w2v_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-95-eb1086c4c89d>\u001b[0m in \u001b[0;36mupdate_w2v_weights\u001b[1;34m(center_embeddings, context_embeddings, center_word, context_word, label, learning_rate)\u001b[0m\n\u001b[0;32m      8\u001b[0m def update_w2v_weights(center_embeddings, context_embeddings, \n\u001b[0;32m      9\u001b[0m                       center_word, context_word, label, learning_rate):\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter_embeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcenter_word\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_embeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcontext_word\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "w = [0.9836099232994968, 0.3847689688960674, 0.033312247867206435]\n",
    "d = [0.882545488649187, 0.6223076699449618, 0.1633041302523962]\n",
    "\n",
    "center_embeddings = [[0.3449417709491044, 0.6762047256081501, 0.9583446027893963], [0.6247126159157468, 0.22038323197740317, 0.29717611444948355], [0.9836099232994968, 0.3847689688960674, 0.033312247867206435], [0.4217704869846559, 0.0023859008971685025, 0.009686915033163657], [0.6933070658521228, 0.9705089533296152, 0.9189360293193337], [0.024858486425111903, 0.11331113152689753, 0.6492144300167894], [0.7861289466352543, 0.227319130535791, 0.8165251907260063], [0.7672181161105678, 0.04865001026002924, 0.07514404284170773]]\n",
    "context_embeddings = [[0.4628817426583818, 0.7747296319956671, 0.1374808935513827], [0.17026823169513283, 0.4094733988461122, 0.3175531656197459], [0.2910876746161247, 0.6340566555548147, 0.23158010794029804], [0.8449042648180852, 0.4796593509107806, 0.11278090182290745], [0.049097778744511156, 0.6254116250148337, 0.13038703647472905], [0.882545488649187, 0.6223076699449618, 0.1633041302523962], [0.6704032810194875, 0.941803340812521, 0.7358646489592193], [0.9875878745059805, 0.17935677165390562, 0.6798846454394736]]\n",
    "label = 2\n",
    "learning_rate = 5\n",
    "def update_w2v_weights(center_embeddings, context_embeddings, \n",
    "                      center_word, context_word, label, learning_rate):\n",
    "    w = np.array(center_embeddings[center_word])\n",
    "    d = np.array(context_embeddings[context_word])\n",
    "    \n",
    "    diff_d = -(label - (1/(1 + np.exp(-sum(w * d))))) * w\n",
    "    diff_w = -(label - (1/(1 + np.exp(-sum(w * d))))) * d\n",
    "    center_embeddings[center_word] = center_embeddings[center_word] - diff_w * learning_rate\n",
    "    context_embeddings[context_word] = context_embeddings[context_word] - diff_d * learning_rate\n",
    "    \n",
    "    return center_embeddings[center_word], context_embeddings[context_word]\n",
    "\n",
    "update_w2v_weights(center_embeddings, context_embeddings, w, d, label, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([1, 10, 12], 2, 1), ([1, 10, 12], 2, 0), ([1, 10, 12], 1, 0), ([2, 20], 1, 1), ([2, 20], 2, 0), ([2, 20], 4, 0), ([2, 20], 0, 1), ([2, 20], 3, 0), ([2, 20], 0, 0), ([0, 17], 2, 1), ([0, 17], 1, 0), ([0, 17], 1, 0), ([0, 17], 1, 1), ([0, 17], 2, 0), ([0, 17], 2, 0), ([1, 10, 12], 0, 1), ([1, 10, 12], 0, 0), ([1, 10, 12], 4, 0), ([1, 10, 12], 4, 1), ([1, 10, 12], 2, 0), ([1, 10, 12], 4, 0), ([4], 1, 1), ([4], 2, 0), ([4], 4, 0), ([4], 0, 1), ([4], 4, 0), ([4], 3, 0), ([0, 17], 4, 1), ([0, 17], 4, 0), ([0, 17], 4, 0), ([0, 17], 4, 1), ([0, 17], 0, 0), ([0, 17], 2, 0), ([4], 0, 1), ([4], 3, 0), ([4], 2, 0), ([4], 1, 1), ([4], 3, 0), ([4], 4, 0), ([1, 10, 12], 4, 1), ([1, 10, 12], 0, 0), ([1, 10, 12], 1, 0), ([1, 10, 12], 5, 1), ([1, 10, 12], 3, 0), ([1, 10, 12], 3, 0), ([5, 11, 7], 1, 1), ([5, 11, 7], 0, 0), ([5, 11, 7], 3, 0), ([5, 11, 7], 4, 1), ([5, 11, 7], 3, 0), ([5, 11, 7], 2, 0), ([4], 5, 1), ([4], 0, 0), ([4], 0, 0), ([4], 5, 1), ([4], 0, 0), ([4], 3, 0), ([5, 11, 7], 4, 1), ([5, 11, 7], 2, 0), ([5, 11, 7], 4, 0), ([5, 11, 7], 4, 1), ([5, 11, 7], 2, 0), ([5, 11, 7], 2, 0), ([4], 5, 1), ([4], 1, 0), ([4], 2, 0), ([4], 5, 1), ([4], 0, 0), ([4], 0, 0), ([5, 11, 7], 4, 1), ([5, 11, 7], 3, 0), ([5, 11, 7], 4, 0), ([5, 11, 7], 1, 1), ([5, 11, 7], 0, 0), ([5, 11, 7], 4, 0), ([1, 10, 12], 5, 1), ([1, 10, 12], 2, 0), ([1, 10, 12], 0, 0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntext - list of integer numbers - ids of tokens in text\\nwindow_size - odd integer - width of window\\nvocab_size - positive integer - number of tokens in vocabulary\\nns_rate - positive integer - number of negative tokens to sample per one positive sample\\ntoken2subwords - list of lists of int - i-th sublist contains list of identifiers of n-grams for token #i (list of subword units)\\n\\nreturns list of training samples (CenterSubwords, CtxWord, Label)\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [1, 2, 0, 1, 4, 0, 4, 1, 5, 4, 5, 4, 5, 1]\n",
    "window_size = 3\n",
    "vocab_size = 6\n",
    "ns_rate = 2\n",
    "token2subwords = [[17], [10, 12], [20, 20], [7, 13], [], [7, 11]]\n",
    "\n",
    "def generate_ft_sgns_samples(text, window_size, vocab_size, ns_rate, token2subwords):\n",
    "    temp = []\n",
    "    for i in range(0, len(text)):\n",
    "        for j in range(1, window_size//2+1):\n",
    "            if ((i-j) >= 0):\n",
    "                temp.append(tuple((list([text[i]]) + list(set(token2subwords[text[i]])), text[i-j], 1)))\n",
    "                for m in range(0, ns_rate):\n",
    "                    temp.append(tuple((list([text[i]]) + list(set(token2subwords[text[i]])),\n",
    "                                       np.random.randint(0, vocab_size-1), 0)))\n",
    "            if ((i+j) < len(text)):\n",
    "                temp.append(tuple((list([text[i]]) + list(set(token2subwords[text[i]])), text[i+j], 1)))\n",
    "                for m in range(0, ns_rate):\n",
    "                    temp.append(tuple((list([text[i]]) + list(set(token2subwords[text[i]])),\n",
    "                                       np.random.randint(0, vocab_size-1), 0)))\n",
    "    return temp\n",
    "\n",
    "# [1,                                                               2,                                0,]\n",
    "# [([1, 10, 12], 2, 1), ([1, 10, 12], 5, 0), ([1, 10, 12], 2, 0), \n",
    "# ([2, 20], 1, 1), ([2, 20], 0, 0), ([2, 20], 5, 0)]\n",
    "\n",
    "print(generate_ft_sgns_samples(text, window_size, vocab_size, ns_rate, token2subwords))\n",
    "\n",
    "\"\"\"\n",
    "text - list of integer numbers - ids of tokens in text\n",
    "window_size - odd integer - width of window\n",
    "vocab_size - positive integer - number of tokens in vocabulary\n",
    "ns_rate - positive integer - number of negative tokens to sample per one positive sample\n",
    "token2subwords - list of lists of int - i-th sublist contains list of identifiers of n-grams for token #i (list of subword units)\n",
    "\n",
    "returns list of training samples (CenterSubwords, CtxWord, Label)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4]\n",
      "[(33, 55), 4, 4, 4]\n",
      "[(33, 55), 4, 4, 4, (11,)]\n"
     ]
    }
   ],
   "source": [
    "x = [4,4]\n",
    "x.append(4)\n",
    "print(x)\n",
    "a = (33,55)\n",
    "x.insert(0, a)\n",
    "print(x)\n",
    "z = [11,11]\n",
    "\n",
    "x.append(tuple(set(z)))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "w =                  [0.9836099232994968, 0.3847689688960674, 0.033312247867206435]\n",
    "\n",
    "d =                  [0.882545488649187, 0.6223076699449618, 0.1633041302523962]\n",
    "\n",
    "center_embeddings = [[0.3449417709491044, 0.6762047256081501, 0.9583446027893963], \n",
    "                     [0.6247126159157468, 0.22038323197740317, 0.29717611444948355], \n",
    "                     [0.9836099232994968, 0.3847689688960674, 0.033312247867206435], \n",
    "                     [0.4217704869846559, 0.0023859008971685025, 0.009686915033163657], \n",
    "                     [0.6933070658521228, 0.9705089533296152, 0.9189360293193337], \n",
    "                     [0.024858486425111903, 0.11331113152689753, 0.6492144300167894], \n",
    "                     [0.7861289466352543, 0.227319130535791, 0.8165251907260063], \n",
    "                     [0.7672181161105678, 0.04865001026002924, 0.07514404284170773]]\n",
    "\n",
    "context_embeddings = [[0.4628817426583818, 0.7747296319956671, 0.1374808935513827], \n",
    "                      [0.17026823169513283, 0.4094733988461122, 0.3175531656197459], \n",
    "                      [0.2910876746161247, 0.6340566555548147, 0.23158010794029804], \n",
    "                      [0.8449042648180852, 0.4796593509107806, 0.11278090182290745], \n",
    "                      [0.049097778744511156, 0.6254116250148337, 0.13038703647472905], \n",
    "                      [0.882545488649187, 0.6223076699449618, 0.1633041302523962], \n",
    "                      [0.6704032810194875, 0.941803340812521, 0.7358646489592193], \n",
    "                      [0.9875878745059805, 0.17935677165390562, 0.6798846454394736]]\n",
    "\n",
    "label = 2\n",
    "learning_rate = 5\n",
    "\n",
    "# def update_w2v_weights(center_embeddings, context_embeddings, \n",
    "#                       center_word, context_word, label, learning_rate):\n",
    "#     w = np.array(center_embeddings[center_word])\n",
    "#     d = np.array(context_embeddings[context_word])\n",
    "    \n",
    "#     diff_d = -(label - (1/(1 + np.exp(-sum(w * d))))) * w\n",
    "#     diff_w = -(label - (1/(1 + np.exp(-sum(w * d))))) * d\n",
    "#     center_embeddings[center_word] = center_embeddings[center_word] - diff_w * learning_rate\n",
    "#     context_embeddings[context_word] = context_embeddings[context_word] - diff_d * learning_rate\n",
    "    \n",
    "#     return center_embeddings[center_word], context_embeddings[context_word]\n",
    "\n",
    "# update_w2v_weights(center_embeddings, context_embeddings, w, d, label, learning_rate)\n",
    "\n",
    "label = 1\n",
    "\n",
    "def update_ft_weights(center_embeddings, context_embeddings,\n",
    "                      center_subwords, context_word, label, learning_rate):\n",
    "    \n",
    "    w = np.array(center_embeddings[center_subwords])\n",
    "    d = np.array(context_embeddings[context_word])\n",
    "    mean_w = np.mean(w, axis=0)\n",
    "\n",
    "    diff_d = -(label - (1/(1 + np.exp(-sum(mean_w * d ))))) * mean_w\n",
    "    diff_w = -(label - (1/(1 + np.exp(-sum(mean_w * d ))))) * d / len(center_subwords)\n",
    "    center_embeddings[center_subwords] = center_embeddings[center_subwords] - diff_w * learning_rate\n",
    "    context_embeddings[context_word] = context_embeddings[context_word] - diff_d * learning_rate\n",
    "    \n",
    "    return center_embeddings[center_subwords], context_embeddings[context_word]    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "(28, 5)\n",
      "(28, 5)\n"
     ]
    }
   ],
   "source": [
    "center_embeddings = np.array([[0.07217140995735816, 0.9807495045952024, 0.5888650678318127, 0.9419020475323008, 0.9698687137771355], \n",
    "                     [0.17481764801167854, 0.9598681333667267, 0.8615416075076997, 0.6649845254089604, 0.14272822189820067], \n",
    "                     [0.695257160390079, 0.6252124583357915, 0.788572884360212, 0.5407620598434707, 0.4742760619803522], \n",
    "                     [0.3720755825170682, 0.8734430653555122, 0.29388553936147677, 0.7833976055802006, 0.11647446813597206], \n",
    "                     [0.4793503066165381, 0.7731679392102295, 0.6466062364447424, 0.5834632727525674, 0.16975097768580916], \n",
    "                     [0.46855676928071344, 0.7440440871653314, 0.5968916205486556, 0.6949993371605877, 0.9995564750677164], [0.3995517204225809, 0.30217048674177027, 0.6934836340605662, 0.5025452046745376, 0.43990420866402447], [0.6233285824044058, 0.7510765715859197, 0.8764982899024905, 0.42892241183749247, 0.9241569354174014], [0.21063022873083803, 0.979366603599722, 0.07879437255385402, 0.7103116511451802, 0.298121842692622], [0.7991181799927396, 0.8700912396205017, 0.4936455488806514, 0.9306352063022928, 0.671689987782089], [0.11245515636577097, 0.2591385008756272, 0.38393130144123977, 0.5927928993875077, 0.3343301767582757], [0.027340724019638274, 0.15461071231349877, 0.7955192467457007, 0.050624838697975516, 0.26136570172628426], [0.7825083895933859, 0.9046538942978853, 0.4559636175207443, 0.733829258685726, 0.022174763292638677], [0.6968176063951074, 0.47974647096747125, 0.8885207189970179, 0.016167994434510558, 0.13260182909882334], [0.5947903955259933, 0.07459974351651177, 0.11391699485528617, 0.823474357110585, 0.4918622459339238], [0.6272760016913231, 0.2711994820963495, 0.24338892914238242, 0.7731707300677505, 0.03720128542002399], [0.8640858092433228, 0.027663971153230382, 0.9271422334467209, 0.37457369227183035, 0.17413436429736662], [0.4878584763813121, 0.5022845803948351, 0.13899660663745628, 0.8353408935052742, 0.48314336609381436], [0.8197910105251979, 0.5371430936015362, 0.12965724315376936, 0.06244349080403733, 0.9558816248633216], [0.5929477505385994, 0.36687167726065173, 0.42925321480480627, 0.8435274356179648, 0.8550018469714032], [0.45785273815309, 0.008764229829187009, 0.6840407156586629, 0.04831125277736026, 0.14609911971743395], [0.1579479219010974, 0.1298470924838635, 0.8283362978065627, 0.9140741421274726, 0.7516395431217443], [0.01139316661353773, 0.6980229640742956, 0.45528806869472405, 0.7653990849713008, 0.24848012670857944], [0.8750941097872984, 0.6964598870452183, 0.6675389863133752, 0.391939718013135, 0.30592620271209714], [0.024161748164975072, 0.6512328549928654, 0.27784751504029503, 0.32588414662648524, 0.4073676483413957], [0.7372935688667617, 0.9743689028772393, 0.26179932035274445, 0.3556999822154028, 0.8234406534181563], [0.9358431512408416, 0.0030942521035778325, 0.7052198210371732, 0.3494249594704901, 0.06494462197366668], [0.027642224051125597, 0.45820907093457997, 0.6172763215932299, 0.03520578036716404, 0.05004091043245007]])\n",
    "print(len(center_embeddings))\n",
    "print(center_embeddings.shape)\n",
    "\n",
    "center_subwords =   [[0.07217140995735816, 0.9807495045952024, 0.5888650678318127, 0.9419020475323008, 0.9698687137771355], \n",
    "                     [0.17481764801167854, 0.9598681333667267, 0.8615416075076997, 0.6649845254089604, 0.14272822189820067], \n",
    "                     [0.695257160390079, 0.6252124583357915, 0.788572884360212, 0.5407620598434707, 0.4742760619803522]]\n",
    "\n",
    "context_embeddings = [[0.3619192935809462, 0.7910582560833153, 0.173840770588212, 0.8486217599360419, 0.09895998679198104], \n",
    "                      [0.9524670374363299, 0.577316446205222, 0.3348594666828074, 0.7987547183235284, 0.710457681490417], [0.8400820704952479, 0.9414962586451427, 0.08399082278691339, 0.425927381574433, 0.6304514720560764], [0.5331686510681622, 0.2751366715811131, 0.8329999135745643, 0.2770290564458684, 0.020564166091874392], [0.9852792048968001, 0.922320208232837, 0.7297936992308128, 0.20212997935663524, 0.5277458149323955], [0.43383566311415755, 0.14151987203148808, 0.3267585826852797, 0.8796734627573763, 0.14253685112772174], [0.24559727482999572, 0.3015598034026842, 0.12351719983998721, 0.6141130319406622, 0.9210871618079258], [0.21915908704207665, 0.9809645232509783, 0.8685879466971278, 0.9956335594634693, 0.0441562419906687], [0.24988758739587902, 0.42298807118368675, 0.01922872769211703, 0.02806386746602596, 0.2821901214584819], [0.43997555452635384, 0.5078839449569567, 0.812607950040521, 0.9998014106280365, 0.1559607489614684], [0.9092151190046189, 0.5930002929595868, 0.315159378929991, 0.4052299042409616, 0.984475831988958], [0.7836990450026143, 0.002466529016497798, 0.8465916260137056, 0.7227126698344118, 0.5087557482398855], [0.4125921074144525, 0.5582795115000383, 0.889307828978137, 0.928416977596577, 0.8437462138575066], [0.11810981794872477, 0.07787452990697508, 0.3907338451314212, 0.6841828899516664, 0.4547615738832046], [0.4977766315279062, 0.09878866849137813, 0.0622140049250518, 0.9008881823827194, 0.3694055807903669], [0.12415427540834822, 0.01064247175537103, 0.1439469061372417, 0.43996173718103593, 0.3846553735294024], [0.36544315427420426, 0.6651402425072226, 0.3837201693785094, 0.54713466624535, 0.6925194086063208], [0.8217730539154436, 0.7380601103419114, 0.4790971996703556, 0.935248458815274, 0.6385239169547122], [0.4884363834477089, 0.783319748626155, 0.018212966919229467, 0.03662832627793777, 0.03532160993715294], [0.6820505211290306, 0.25769913167047753, 0.9677388106523852, 0.4471332422618759, 0.7731319006564568], [0.3695513424667971, 0.5118113495291988, 0.1721439269100805, 0.09451631327113852, 0.8369170475041434], [0.7918542552021289, 0.0245240901264403, 0.6658133706965796, 0.9740885323982209, 0.02660284500887522], [0.5604137104962275, 0.5643917632639455, 0.6756476068355826, 0.9466913679034125, 0.21062462975598062], [0.7306868573812846, 0.7573083135261555, 0.9450278665003865, 0.9649869335038909, 0.1262321882978371], [0.6830284536315845, 0.7383035166437748, 0.7985226892860073, 0.005247820534787007, 0.6886083391552933], [0.6905561126225058, 0.3220803445510755, 0.8885006766287556, 0.32709316933290455, 0.9126547743770385], [0.26866358146648694, 0.9355232286537734, 0.5254946965960933, 0.6487428023364232, 0.9405298594379049], [0.33881123962516546, 0.6820622877451537, 0.3053828831926755, 0.9229486901650673, 0.5450270097149575]]\n",
    "print(np.array(context_embeddings).shape)\n",
    "\n",
    "w = center_embeddings[1:4]\n",
    "# print(w)\n",
    "# w_mean = np.mean(w, axis=1)\n",
    "# print(np.exp(-sum(sum(np.mean(w, axis=1)) * np.array(context_embeddings) / len(center_subwords))))\n",
    "# print(w_mean)\n",
    "# print(np.mean(w, axis=0) * np.array(context_embeddings))\n",
    "\n",
    "w = np.array(center_embeddings[0:3])\n",
    "d = np.array(context_embeddings[1])\n",
    "\n",
    "mean_w = np.mean(w, axis=0)\n",
    "\n",
    "diff_d = -(label - (1/(1 + np.exp(-sum(mean_w * d ))))) * mean_w\n",
    "diff_w = -(label - (1/(1 + np.exp(-sum(mean_w * d ))))) * d / len(center_subwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (1, 2)\t2\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t2\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "texts = [[0, 2, 2, 2, 0, 0], [1, 1, 2, 1, 1], [2, 2, 1, 1]]\n",
    "vocab_size = 3\n",
    "\n",
    "# [[0.0, 0.0, 1.0], [0.0, 0.0, 2.0], [1.0, 2.0, 0.0]]\n",
    "\n",
    "def generate_coocurrence_matrix(texts, vocab_size):\n",
    "#     result = scipy.sparse.dok_matrix((len(texts), vocab_size), dtype='float32')\n",
    "#     for text_i, text in enumerate(texts):\n",
    "#         for token in text:\n",
    "# #             if token != text_i:\n",
    "#             result[text_i, token] = 1\n",
    "#     result = result.T * result\n",
    "\n",
    "#     for i in range(result.shape[0]):\n",
    "#         for j in range(result.shape[1]):\n",
    "#             if i == j:\n",
    "#                 result[i,j] = 0\n",
    "                \n",
    "                \n",
    "#     return result\n",
    "    return scipy.sparse.dok_matrix([[sum([i in s and j in s for s in texts if i != j])\n",
    "                                     for i in range(vocab_size)] for j in range(vocab_size)])\n",
    "print(generate_coocurrence_matrix(texts, vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 8.95053674,  9.78421699,  7.04659033, 10.84275563,  7.14095734,\n",
       "          9.28518013],\n",
       "        [ 6.10478073,  8.54911951,  5.62744168,  8.44868707,  7.2939297 ,\n",
       "          7.67415232],\n",
       "        [ 8.16000668,  7.24712209,  6.119497  ,  8.88903513,  6.62148918,\n",
       "          6.27791411],\n",
       "        [ 5.81403257,  6.76165465,  5.35921546,  7.37251922,  5.2394298 ,\n",
       "          6.48671592],\n",
       "        [ 4.52284669,  3.26669374,  3.29102528,  4.70060677,  2.87392822,\n",
       "          3.70059413],\n",
       "        [ 3.67017701,  6.50073958,  2.81813238,  5.4953125 ,  5.11602944,\n",
       "          5.45737965],\n",
       "        [ 3.27279561,  4.98143878,  2.49940035,  4.66184866,  3.08158999,\n",
       "          3.07133447],\n",
       "        [ 5.90341239, 11.03240946,  4.60546295, 10.69715533,  9.17299267,\n",
       "          5.6164864 ],\n",
       "        [ 8.07463391, 13.44913768,  8.15864833, 13.41309639,  9.65435427,\n",
       "          9.05913661],\n",
       "        [ 7.35776441, 11.16159718,  6.06622692, 10.58937619,  9.05736246,\n",
       "          7.79997853],\n",
       "        [ 8.61599775, 14.90918211,  6.21892036, 14.5180915 , 12.86062175,\n",
       "          9.80512968],\n",
       "        [ 4.40488422,  6.7586956 ,  3.29056936,  6.56817469,  5.38460095,\n",
       "          4.64423551],\n",
       "        [ 4.81465103,  8.15175469,  3.89281052,  7.14483476,  6.59586502,\n",
       "          7.07022734],\n",
       "        [ 8.42975307, 10.29329223,  7.37632868, 10.81739364,  8.05369289,\n",
       "          7.78383834],\n",
       "        [ 8.95888059, 10.72398018,  6.79876931, 11.0002781 ,  9.00041628,\n",
       "         10.16483757],\n",
       "        [ 5.54281813,  5.81467565,  3.67777745,  7.67044335,  5.71684576,\n",
       "          2.9264318 ],\n",
       "        [ 6.02193264,  8.65366498,  6.12488095,  8.25107597,  4.80494954,\n",
       "          7.3655275 ],\n",
       "        [ 4.97514407,  8.91454191,  3.25293121,  7.98631934,  6.11504975,\n",
       "          6.15446226],\n",
       "        [ 5.04639602,  6.59449095,  4.6459616 ,  6.64142937,  4.80937094,\n",
       "          7.14935364],\n",
       "        [ 5.72183854, 10.98875735,  4.35757847, 10.0309886 ,  9.20063411,\n",
       "          6.95257442],\n",
       "        [ 5.39066912, 10.61356905,  4.09215201,  9.91706627,  8.60010939,\n",
       "          6.38083362],\n",
       "        [ 2.69760803,  6.80439114,  2.65050455,  5.36889949,  4.00336094,\n",
       "          4.71303226],\n",
       "        [ 0.58100646,  3.55892413,  1.1224419 ,  3.71015277,  3.2693652 ,\n",
       "          1.85522716],\n",
       "        [ 7.92108319, 14.26502776,  9.04044663, 13.22900826,  9.57159834,\n",
       "         11.13000233],\n",
       "        [ 4.8572903 ,  6.32170578,  4.53350508,  6.02288278,  4.44266995,\n",
       "          4.4299025 ],\n",
       "        [ 3.41369789,  5.71295894,  2.5088135 ,  5.20121086,  5.2828012 ,\n",
       "          3.60342178]]),\n",
       " array([[13.96137382,  2.06167302,  0.84618099, 15.37591275,  8.07546408,\n",
       "         15.55208386],\n",
       "        [ 2.92508338,  2.8838939 , 13.86587408,  2.78990509,  6.89526836,\n",
       "         10.03256399],\n",
       "        [12.09256647,  2.81151058, 14.60472019, 10.93923806,  4.44596967,\n",
       "          7.88800131],\n",
       "        [ 2.89656539,  9.00809201,  6.18107995, 11.29911989, 10.69181237,\n",
       "          9.61971336],\n",
       "        [ 4.99320156,  2.64010457,  6.45094906,  8.40148971,  0.59788311,\n",
       "          7.25530498],\n",
       "        [ 7.12536697,  8.17008885,  4.54749776,  5.16522494,  5.15589036,\n",
       "          7.43871353],\n",
       "        [ 0.53455553,  6.8052165 ,  0.49441691,  2.49675496,  5.0699499 ,\n",
       "          1.06051892],\n",
       "        [10.19972948, 15.49596951, 15.27853675,  7.84256731,  9.74446819,\n",
       "         12.1664221 ],\n",
       "        [12.70547122,  5.68394778, 17.94733128,  7.96433304, 10.56056722,\n",
       "         10.25628343],\n",
       "        [ 4.35695031, 13.57256686, 18.36716943,  1.81199636, 11.39744315,\n",
       "          2.93777367],\n",
       "        [19.2177635 ,  6.99664162, 11.9090353 ,  7.14842522,  8.73487663,\n",
       "         11.21485005],\n",
       "        [ 9.99456625, 10.1643827 ,  7.56313505,  9.6150351 ,  5.55374002,\n",
       "          1.61077873],\n",
       "        [ 6.8962613 ,  4.28213419, 11.38300834,  1.96483474,  8.42239804,\n",
       "          1.30050185],\n",
       "        [ 5.92322983, 11.72555264,  0.71919724,  8.01388808,  7.94362228,\n",
       "          1.99106963],\n",
       "        [ 9.72642951,  2.25396684, 10.35253087,  8.92091603,  3.96183994,\n",
       "          9.73659236],\n",
       "        [ 6.03259873,  4.13237283, 10.53690784, 12.99800354,  3.86777351,\n",
       "          5.56210519],\n",
       "        [ 2.77884942, 12.5871849 ,  0.98604578, 10.60736608,  4.15813235,\n",
       "          7.44789794],\n",
       "        [ 9.2170533 ,  9.12055489,  4.62061447,  2.69149118,  1.56572937,\n",
       "          2.80097062],\n",
       "        [ 4.45719629,  6.13319582, 10.3751408 , 10.16211707,  8.61749377,\n",
       "         10.29017354],\n",
       "        [ 5.43187077, 13.06182198, 15.2111288 ,  3.72535263, 15.589736  ,\n",
       "          3.76978008],\n",
       "        [10.0198549 , 11.96812132, 11.56173643,  8.1322978 ,  3.17172625,\n",
       "         15.07555541],\n",
       "        [ 3.53637781,  7.34539187,  5.46194851,  2.99559419,  1.2929889 ,\n",
       "          4.99216876],\n",
       "        [ 1.96361046,  1.73452354,  3.71263721,  3.30320369,  1.85315362,\n",
       "          3.28457751],\n",
       "        [ 1.48006437, 12.82549302, 14.32035618,  9.68418612, 10.40774212,\n",
       "          6.49370452],\n",
       "        [ 3.84535721,  7.55421472,  6.77334626,  1.92084979,  9.61551921,\n",
       "          6.33777169],\n",
       "        [ 3.94833597,  8.56617381,  1.32106551,  2.5141413 ,  7.80061476,\n",
       "          6.83371695]]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[72, 67, 24, 81, 52, 43, 49, 12, 84, 77, 22, 66, 66, 0, 59, 4, 71, 78, 37, 69, 39, 63, 68, 36, 97, 17], [72, 38, 34, 43, 11, 46, 91, 96, 43, 4, 80, 77, 19, 18, 39, 8, 43, 58, 59, 43, 40, 55, 14, 96, 90, 43], [83, 82, 22, 93, 5, 17, 68, 30, 2, 67, 7, 8, 34, 2, 88, 66, 31, 52, 96, 13, 9, 83, 3, 9, 91, 15], [73, 25, 40, 82, 42, 30, 79, 77, 15, 76, 65, 6, 7, 44, 98, 88, 65, 74, 33, 48, 61, 54, 64, 28, 49, 38], [47, 41, 2, 54, 5, 13, 36, 0, 97, 15, 80, 90, 38, 27, 24, 31, 32, 20, 77, 20, 8, 11, 24, 19, 77, 23], [55, 26, 42, 5, 98, 87, 36, 1, 11, 19, 57, 68, 92, 49, 98, 9, 98, 24, 0, 13, 14, 90, 10, 51, 30, 30], [98, 12, 2, 66, 27, 12, 12, 60, 46, 71, 89, 82, 75, 49, 5, 77, 52, 96, 29, 32, 51, 71, 45, 16, 74, 12], [18, 92, 95, 62, 51, 65, 1, 49, 51, 62, 16, 64, 97, 48, 78, 14, 90, 50, 43, 49, 59, 11, 75, 50, 60, 2], [47, 45, 88, 78, 93, 30, 79, 20, 69, 68, 6, 76, 41, 3, 57, 98, 62, 6, 65, 53, 7, 9, 76, 96, 19, 88], [45, 73, 39, 70, 21, 62, 82, 13, 14, 72, 8, 23, 99, 49, 33, 80, 21, 67, 37, 31, 38, 48, 40, 61, 61, 67], [61, 86, 91, 61, 13, 88, 79, 56, 78, 87, 91, 94, 37, 14, 15, 44, 91, 3, 6, 23, 15, 85, 18, 58, 11, 4], [50, 28, 55, 44, 21, 62, 98, 64, 85, 84, 4, 31, 59, 16, 51, 11, 37, 44, 6, 60, 47, 54, 70, 29, 32, 74], [39, 6, 17, 54, 15, 71, 24, 94, 5, 16, 15, 74, 43, 98, 75, 10, 79, 78, 99, 47, 99, 4, 22, 90, 12, 19], [74, 51, 67, 72, 21, 9, 57, 50, 0, 43, 80, 91, 58, 46, 92, 98, 11, 4, 36, 31, 90, 90, 91, 52, 68, 63], [95, 76, 24, 52, 3, 71, 19, 75, 34, 92, 83, 15, 77, 12, 96, 58, 63, 68, 75, 9, 28, 44, 30, 94, 67, 49], [22, 93, 33, 77, 2, 9, 3, 3, 47, 56, 84, 70, 15, 81, 16, 49, 20, 95, 18, 22, 98, 3, 77, 27, 1, 13], [45, 63, 34, 0, 75, 45, 30, 23, 7, 7, 80, 62, 34, 11, 41, 16, 45, 6, 11, 21, 18, 55, 7, 24, 18, 70], [13, 7, 21, 85, 29, 53, 56, 83, 63, 89, 18, 67, 93, 73, 37, 3, 55, 65, 16, 72, 6, 80, 0, 39, 51, 24], [72, 23, 9, 56, 60, 88, 69, 6, 8, 92, 3, 44, 29, 5, 58, 58, 55, 24, 48, 57, 28, 69, 64, 72, 58, 98], [20, 56, 52, 74, 27, 95, 85, 20, 7, 52, 8, 93, 76, 53, 62, 54, 34, 25, 89, 38, 85, 29, 38, 18, 1, 28], [30, 97, 74, 11, 36, 92, 55, 74, 34, 29, 12, 40, 61, 69, 54, 72, 14, 64, 73, 75, 75, 4, 37, 47, 17, 29], [7, 18, 25, 6, 51, 63, 63, 53, 38, 96, 19, 56, 36, 35, 75, 99, 32, 28, 68, 14, 55, 9, 3, 19, 9, 59], [0, 98, 57, 98, 13, 25, 55, 56, 58, 37, 30, 90, 51, 71, 10, 36, 58, 94, 32, 80, 95, 44, 40, 82, 99, 6], [74, 28, 93, 37, 81, 54, 92, 89, 52, 96, 93, 8, 65, 82, 7, 14, 75, 0, 45, 59, 15, 17, 85, 87, 10, 52], [10, 74, 13, 23, 56, 25, 66, 59, 86, 39, 47, 72, 92, 28, 23, 75, 23, 18, 5, 20, 36, 52, 42, 56, 20, 7], [32, 37, 58, 20, 3, 33, 76, 92, 36, 73, 90, 53, 82, 78, 6, 66, 11, 33, 64, 68, 51, 76, 94, 94, 74, 88]])\n",
    "w = np.array([[0.7236403458959406, 0.0956019387576047, 0.0025299248050427714, 0.8219024304497274, 0.43253754513562515, 0.8013795226500925], [0.1645225418615962, 0.17254764305062675, 0.915834884927677, 0.15659274788174238, 0.4408801726853846, 0.6712507398638423], [0.7220314060070252, 0.1109087497279424, 0.8673890374761482, 0.6019681601593759, 0.21136092547712715, 0.46410460250177055], [0.2051472970020488, 0.7021578939163269, 0.4920315519905448, 0.8786530949689468, 0.8406582658875078, 0.7656322995670249], [0.5314722945128192, 0.20582039242966288, 0.6649783801689887, 0.9122470167268962, 0.06046820688028054, 0.7640361944809368], [0.8531299103217095, 0.8837919293919477, 0.5584731093192602, 0.5488851769744959, 0.5426259488733682, 0.8101919492091457], [0.014691936047236509, 0.8299297933323541, 0.04420642840864686, 0.19514486051010316, 0.5605834763387445, 0.021425480951998255], [0.6251450063221531, 0.916013278510962, 0.9266733043623226, 0.4314909906070713, 0.5861250222822415, 0.6933275681854775], [0.613436662402963, 0.25971014970117345, 0.8516017571376222, 0.3946078968050868, 0.5030576607821642, 0.4947379037657953], [0.1831704150579163, 0.7027400367924451, 0.9687380255252486, 0.05161874874595729, 0.5662001008903554, 0.1163342848387866], [0.7871817922619593, 0.2744881375377821, 0.47927673745333677, 0.29916960674176196, 0.36165825794500894, 0.4473132902029585], [0.9460136327515588, 0.9784510345542305, 0.7292583652396575, 0.9967710630754123, 0.5222338378761943, 0.15774056366446398], [0.5663154377790205, 0.31992559317458047, 0.895903341426127, 0.10800834113175917, 0.7025174488794499, 0.09983260287294515], [0.2870859802344229, 0.6124244361792336, 0.03043370710190285, 0.4177754705816856, 0.41076530192454186, 0.059229404317664214], [0.453421549409623, 0.10006035499361832, 0.4729640823042591, 0.4187735846604017, 0.19252902582118436, 0.4571615927038022], [0.4717366823003555, 0.311470963714212, 0.7563429074261462, 0.9450429903711869, 0.23851560864324461, 0.4264206092799121], [0.14209483434392234, 0.9545183136517666, 0.02853067102355411, 0.8397788414889452, 0.28747164060068653, 0.5890799959267197], [0.7137144457967627, 0.7108041311984524, 0.3391605131543025, 0.18466650700703768, 0.07037926283668172, 0.1691030355977058], [0.4181167385409663, 0.5733773938988352, 0.9308794863064511, 0.955104551017489, 0.7472618752255964, 0.9106883383537705], [0.29209827546854006, 0.7950653331872178, 0.9314779081831699, 0.2137419943082265, 0.9590688802321072, 0.21779623076769017], [0.6414528631722118, 0.7772400748403205, 0.7240597746441493, 0.4846785371953165, 0.20903895145878393, 0.9928711008461597], [0.4987552039133927, 0.966261456826001, 0.6392910461562884, 0.3891694028095307, 0.14376415691424704, 0.5654942409405452], [0.39062876410463865, 0.4372793328535669, 0.9066881332880398, 0.928194141998039, 0.26891611788606773, 0.970014111003586], [0.05753018657343756, 0.5987554892139141, 0.6695393400712614, 0.4342378657370556, 0.5068004463455815, 0.28913437767829675], [0.31284712702847906, 0.6696586256781413, 0.6349611781499843, 0.11008282689008553, 0.9000387199581723, 0.5893732652223279], [0.38771861901614457, 0.9275236976874062, 0.1507893346167909, 0.2649576462980838, 0.8917999241041804, 0.7060665522096253]])\n",
    "d = np.array([[0.7146175764456325, 0.31161087332596693, 0.799868898982844, 0.3303984762074823, 0.15755367025489198, 0.8822561515814714], [0.48324415449065805, 0.32294633607735035, 0.273076894762348, 0.46575965932905583, 0.35173647464295466, 0.0698782343365999], [0.05951092454514029, 0.9631544906381114, 0.14919875559361273, 0.9071033838543416, 0.9235221236014998, 0.15343960980130578], [0.37667471994346735, 0.3832592710693109, 0.1372971042292026, 0.5063394603470396, 0.3657347277059969, 0.21520394748123772], [0.5589413502705171, 0.9228726685280682, 0.9028006349689756, 0.7902921185261006, 0.09337560160131464, 0.8806823905125992], [0.19078196327854235, 0.9862705503057667, 0.00800242331367751, 0.7036641885324555, 0.7452071471082209, 0.85314563397203], [0.42059808696733225, 0.3678976649279547, 0.15153142787888962, 0.9831212856723789, 0.7218055186807681, 0.8943329971799489], [0.058672278269596756, 0.6364681756816949, 0.24610924719747507, 0.8429515887557353, 0.23639035927773622, 0.9193123017124043], [0.3667295853360063, 0.46010540148263646, 0.818107188288508, 0.027140526241385965, 0.4420026102807323, 0.3050634480740779], [0.9602073143407148, 0.5408373879572825, 0.4027285042008486, 0.854769594232319, 0.8977332204421882, 0.7804511190784789], [0.9554030213710992, 0.6286064807931032, 0.7899715293283952, 0.20778805629585584, 0.34452317136784105, 0.8373278109724016], [0.9511367017094053, 0.8108673965379353, 0.5917802839407773, 0.08638924272725734, 0.5614389008614823, 0.10285577516634681], [0.15293610366355237, 0.4726630546010566, 0.7151593451811216, 0.6787398883364194, 0.05726564336395312, 0.11175850750236216], [0.5284613368117816, 0.2171952870224766, 0.14730305464381344, 0.16327154211081985, 0.22473713798444594, 0.8780618686814565], [0.6229749344457463, 0.2450307938022901, 0.856716114606889, 0.5130970556519491, 0.09638792050417233, 0.5580480219996736], [0.02557257524793899, 0.16614696997999867, 0.9057474930205891, 0.9639638373151679, 0.8305505098688646, 0.13212730388642224], [0.9945224728362285, 0.601015567237635, 0.627777689771871, 0.062014306890884385, 0.5482657713187832, 0.050645865034282034], [0.222530564647055, 0.16270913407631815, 0.3463743065572499, 0.3642479732760492, 0.6787809827842912, 0.6698646733332234], [0.0514618465561959, 0.09146560753484756, 0.5663782403169225, 0.09809277695721963, 0.7435268283749681, 0.6941669527997202], [0.7220783710745816, 0.242189075941737, 0.19197963437514165, 0.2789768605860322, 0.1257100212184865, 0.25803379668907667], [0.5231678066470311, 0.4611093289035184, 0.8420569136872692, 0.9566490894261072, 0.07691192438283945, 0.37613366065780873], [0.010481514678729265, 0.5145103851754453, 0.9425491945781952, 0.24440293940943314, 0.2766636476384883, 0.9944680222564074], [0.7081598239606982, 0.3291415847107684, 0.7986116830970068, 0.32005951294163504, 0.988878016430301, 0.16702718654180948], [0.3281899603978248, 0.8371583970360936, 0.914781121298489, 0.9898376984561366, 0.2605393835200668, 0.7046307961318979], [0.6669241697435273, 0.7506837943872975, 0.3223310011040579, 0.8024412673323509, 0.47139557621217376, 0.34991596973647043], [0.6981065171211724, 0.7907802796637423, 0.05700463849852977, 0.29301210116680565, 0.3246921756526622, 0.9147896908728982]])\n",
    "alpha = 0.5878728651551414\n",
    "max_x = 97\n",
    "learning_rate = 0.8066056621137515\n",
    "\n",
    "def f(x, alpha, max_x):\n",
    "    temp = np.zeros((x.shape[0], x.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            if x[i][j] <= max_x: \n",
    "                temp[i][j] = np.power((x[i][j]/ max_x), alpha)\n",
    "            else:\n",
    "                1\n",
    "    return temp\n",
    "\n",
    "\n",
    "def update_glove_weights(x, w, d, alpha, max_x, learning_rate):\n",
    "    w = np.array(w)\n",
    "    d = np.array(d)\n",
    "    x = np.array(x)\n",
    "    fij = f(x, alpha, max_x)\n",
    "    d_d = np.zeros((x.shape[0], w.shape[1]))\n",
    "    d_w = np.zeros((x.shape[0], w.shape[1]))\n",
    "    for i in range(w.shape[0]):\n",
    "        for j in range(w.shape[1]):\n",
    "            d_d[i] = d_d[i] +  fij[i][j]\\\n",
    "            * (np.log1p(x[i][j]) - np.matmul(w[i][:], d[:][j].T)) * w[i][:]\n",
    "            d_w[i] = d_w[i] +  fij[i][j]\\\n",
    "            * (np.log1p(x[i][j]) - np.matmul(w[i][:], d[:][j].T)) * d[:][j].T\n",
    "            \n",
    "    d_d = - 2 * d_d \n",
    "    d_w = - 2 * d_w\n",
    "#     print(d_w)\n",
    "#     print(d_d)\n",
    "    w = w - d_w * learning_rate\n",
    "    d = d - d_d * learning_rate\n",
    "    return w, d\n",
    "\n",
    "update_glove_weights(x, w, d, alpha, max_x, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]]\n",
      "24\n",
      "[[10  2  3]\n",
      " [ 0  5  6]\n",
      " [ 0  0  9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[10,2,3],[4,5,6],[7,8,9]])\n",
    "print(a)\n",
    "print(np.trace(a))\n",
    "print(np.triu(a))\n",
    "result = np.triu(np.rot90(a)).sum() - np.trace(a)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1622776601683795"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "b = np.array([[4, 3],\n",
    "              [1, 2]])\n",
    "LA.norm(b)\n",
    "point_1 = np.array([4,3])\n",
    "point_2 = np.array([1,2])\n",
    "np.linalg.norm(point_1-point_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, -0.0), (2.0, -0.5028921892757982), (1.0, -0.5422310219843909)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = [[0.7299015792584768, 0.2915364327741303, 0.5307571134639943, 0.3101345732086396, 0.8327085262119636, 0.39018382511314353, 0.678094726221033, 0.12372148102696612, 0.5966533433209616], [0.5411155947267721, 0.046791742239819856, 0.5358832195593092, 0.09894162419462038, 0.6350557173679914, 0.15126161842015717, 0.11375720216711405, 0.46954553941325416, 0.8281402097264261], [0.5323869209381028, 0.2005012376766715, 0.5925043884236925, 0.4621530177251649, 0.3886830034303448, 0.6403738184472031, 0.23320289120963578, 0.43574647265888766, 0.5305633832484254]]\n",
    "\n",
    "query_word_id = 0\n",
    "get_n = 8\n",
    "\n",
    "def get_nearest(embeddings, query_word_id, get_n):\n",
    "    \"\"\"\n",
    "    embeddings - VocabSize x EmbSize - word embeddings\n",
    "    query_word_id - integer - id of query word to find most similar to\n",
    "    get_n - integer - number of most similar words to retrieve\n",
    "\n",
    "    returns list of `get_n` tuples (word_id, similarity) sorted by descending order of similarity value\n",
    "    \"\"\"\n",
    "    query_word = embeddings[query_word_id]\n",
    "    temp = []\n",
    "    embeddings = np.array(embeddings)\n",
    "    \n",
    "    for i in range(embeddings.shape[0]):\n",
    "        temp.append(tuple((float(i), \n",
    "                           -np.linalg.norm(embeddings[i]/np.linalg.norm(embeddings[i])-query_word/np.linalg.norm(query_word)) \n",
    "                                                           )))\n",
    "        \n",
    "    temp = sorted(temp, reverse=True, key=lambda x: x[1])\n",
    "    return temp[0 : get_n]\n",
    "\n",
    "get_nearest(embeddings, query_word_id, get_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 2)\n",
      "(3, 2, 5)\n",
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.53637401, 3.40559783, 3.64203285],\n",
       "       [3.53791755, 3.31563793, 3.19785548],\n",
       "       [3.11553433, 2.6461514 , 2.82923446],\n",
       "       [3.95582621, 2.68487692, 2.35547493],\n",
       "       [3.31545625, 2.55379287, 2.97932928],\n",
       "       [3.23359714, 1.88961059, 2.29726403],\n",
       "       [2.55036376, 2.44108517, 2.06635398],\n",
       "       [3.80066148, 2.76372775, 3.03033055],\n",
       "       [2.87705358, 2.37783992, 2.69971685],\n",
       "       [3.48545989, 1.96369042, 1.96099252],\n",
       "       [3.37079171, 2.66791052, 2.27237898],\n",
       "       [4.17954021, 2.6157867 , 3.36235457]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.array([[[0.8638059436915633, 0.4002290439648929, 0.8174398057982054, 0.34082478315585973, 0.5565832130592809], [0.08497737591188492, 0.7853885140384725, 0.1645895575029136, 0.6294907704137637, 0.8169862258229014]], [[0.21527072709338957, 0.9185427760457524, 0.5167378860756242, 0.12177789993763499, 0.4201289643444214], [0.8389450071463863, 0.6238637143288427, 0.5098771768082815, 0.1436853463091461, 0.12036561608743845]], [[0.8347050184618267, 0.12339875692133984, 0.13629086964943626, 0.623950910768403, 0.7092189295761365], [0.9578703072530402, 0.31612669923975534, 0.44018179806384916, 0.26615330385390035, 0.2745979551030847]]])\n",
    "data = np.array([[0.6685863697825855, 0.9865099796400376], [0.32297881307708, 0.9908870158650515], [0.8359169063921157, 0.5443776713017927], [0.5363888029267118, 0.34755850459471804], [0.5966372342560426, 0.9834742307894673], [0.7371274295314912, 0.03279590013405109], [0.08580648148402137, 0.2850655085982621], [0.584942134340805, 0.7981720699451806], [0.19604496972304086, 0.991819073359733], [0.5622511488322055, 0.07928952553499002], [0.24152151330089744, 0.2865696384305756], [0.882594506643994, 0.5949729821472712], [0.10820233432771786, 0.8549971123651271], [0.18754460128195194, 0.6303661925298489], [0.3551051497971416, 0.9452980688158904], [0.6525044770663634, 0.8054232618991838]])\n",
    "bias = np.array([0.6574440445518804, 0.3253787051567585, 0.3119672663686287])\n",
    "\n",
    "print(data.shape)\n",
    "print(kernel.shape)\n",
    "print(bias.shape)\n",
    "\n",
    "def apply_convolution(data, kernel, bias):\n",
    "\n",
    "    Outlen = data.shape[0] - kernel.shape[2] + 1\n",
    "    OutChannels = kernel.shape[0]\n",
    "    Y = np.zeros([Outlen, OutChannels])\n",
    "    \n",
    "    for pos in range(Outlen):\n",
    "        for oc in range(kernel.shape[0]):\n",
    "            Y[pos, oc] += bias[oc]\n",
    "            for k in range(kernel.shape[2]):\n",
    "                for ic in range(data.shape[1]):\n",
    "                    Y[pos, oc] += data[pos + k, ic] * kernel[oc, ic, k]\n",
    "    return Y\n",
    "apply_convolution(data, kernel, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 3)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[4.536374007375313, 3.40559782717228, 3.6420328514923983], [3.5379175544464094, 3.3156379278173618, 3.197855475391681], [3.11553432527298, 2.6461513962620473, 2.829234462423411], [3.955826212094638, 2.6848769190617205, 2.355474927521796], [3.315456250217841, 2.5537928749371677, 2.979329283784809], [3.2335971417998324, 1.8896105910662777, 2.297264030641381], [2.5503637613247276, 2.441085171765234, 2.066353981430436], [3.8006614791608166, 2.7637277539201435, 3.030330546451793], [2.8770535772488457, 2.377839924681041, 2.6997168451820808], [3.4854598947993667, 1.9636904181843315, 1.9609925225671008], [3.3707917076650484, 2.6679105220798633, 2.272378980117733], [4.179540206172764, 2.615786698404636, 3.36235456621979]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.43015332, 3.25308579, 3.39093181],\n",
       "        [1.89280476, 1.69317539, 1.67862206],\n",
       "        [2.64302071, 2.89671496, 3.49165859]],\n",
       "\n",
       "       [[2.43015332, 3.25308579, 3.39093181],\n",
       "        [1.89280476, 1.69317539, 1.67862206],\n",
       "        [2.64302071, 2.89671496, 3.49165859]]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([[[2.4301533243865463, 3.253085788359958, 3.3909318100218258], [1.8928047647857822, 1.6931753947579833, 1.6786220604803275], [2.643020708074734, 2.8967149590920043, 3.491658593272137]], \n",
    "              [[2.4301533243865463, 3.253085788359958, 3.3909318100218258], [1.8928047647857822, 1.6931753947579833, 1.6786220604803275], [2.643020708074734, 2.8967149590920043, 3.491658593272137]]])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 9\n",
      "[[[2.43015332 3.25308579 3.39093181]\n",
      "  [1.89280476 1.69317539 1.67862206]\n",
      "  [2.64302071 2.89671496 3.49165859]]\n",
      "\n",
      " [[2.43015332 3.25308579 3.39093181]\n",
      "  [1.89280476 1.69317539 1.67862206]\n",
      "  [2.64302071 2.89671496 3.49165859]]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[0.1559846921787793, 0.31890243279158936, 0.4294841981370352], [0.6287087193276831, 0.041166388481120975, 0.0670771539905104], [0.15852860049868056, 0.5535509628878403, 0.7578893631796608], [0.505354018460584, 0.39104507392557886, 0.267830936523598], [0.35352084058390487, 0.09557605719492113, 0.17762289879326898], [0.17895124947325458, 0.2038143268404633, 0.45431038892117714], [0.44910520386366004, 0.28874952266426823, 0.48880576852948343], [0.978917156152191, 0.11927306276379035, 0.6831784491543058], [0.7665547409895508, 0.02661305420346527, 0.662020788170643]])\n",
    "y = np.array([[0.9423069699375323, 2.235723993887441], [1.051430354504024, 2.5441990558270864], [1.3060781439427196, 2.77617352972661], [1.1097986223660692, 2.019161891632857], [0.8312656308401454, 2.1968468090151005], [1.0883546513743934, 3.182136137325698], [1.4545203460970286, 3.3294233853738975]])\n",
    "kernel = np.array([[[0.7285150274194675, 0.13990616439149894, 0.08385531710791316], [0.8119118106104425, 0.19272155988045991, 0.010762309371285528], [0.5242309485683324, 0.33106798748722055, 0.2219888201243384]], [[0.31261137319823096, 0.3951341806652614, 0.954412244770657], [0.5475239344122861, 0.6407966544293683, 0.2840031545245296], [0.9267337670407934, 0.626334029479077, 0.4315268897320006]]])\n",
    "bias = np.array([0.03900532471824536, 0.6619593919342232])\n",
    "\n",
    "# x = np.array([[1,0],[1,1],[0,0]])\n",
    "# kernel = np.array([[[1,1],[1,1]],[[1,1],[1,1]]])\n",
    "# bias = np.array([0,0])\n",
    "\n",
    "\n",
    "def calculate_kernel_grad(x, y, kernel, bias):\n",
    "    \"\"\"\n",
    "    x - InLen x InChannels\n",
    "    y - OutLen x OutChannels\n",
    "    kernel - OutChannels x InChannels x KernelSize\n",
    "    bias - OutChannels\n",
    "\n",
    "    returns OutChannels x InChannels x KernelSize\n",
    "    \"\"\"\n",
    "#     Outlen = data.shape[0] - kernel.shape[2] + 1\n",
    "#     OutChannels = kernel.shape[0]\n",
    "#     InChannels = x.shape[1]\n",
    "#     KernelSize = kernel.shape[2]\n",
    "#     Y = np.zeros([Outlen, OutChannels])\n",
    "    \n",
    "#     for pos in range(Outlen):\n",
    "#         for oc in range(kernel.shape[0]):\n",
    "#             Y[pos, oc] += bias[oc]\n",
    "#             for k in range(kernel.shape[2]):  \n",
    "#                 for ic in range(data.shape[1]):\n",
    "#                     Y[pos, oc] += data[pos + k, ic] * kernel[oc, ic, k]\n",
    "#     return Y    \n",
    "\n",
    "#     W = np.zeros(kernel.shape)\n",
    "    \n",
    "    print(kernel.shape[2], len(data))\n",
    "    res = np.zeros(kernel.shape)\n",
    "    for n in range(kernel.shape[0]):\n",
    "        for i in range(len(data)-kernel.shape[2]+1):\n",
    "            for j in range(kernel.shape[2]):\n",
    "                for c in range(kernel.shape[1]):\n",
    "                     res[n,c,j] += data[i+j, c]\n",
    "    return res    \n",
    "#     for OutChannel in range(OutChannels):\n",
    "#         for Kernel in range(KernelSize):\n",
    "#             for InChannel in range(InChannels):\n",
    "#                 W[OutChannel, InChannel, Kernel] \\\n",
    "#                         += x[OutChannel + Kernel, InChannel] \n",
    "                \n",
    "#     return W\n",
    "#     W = np.zeros(kernel.shape)\n",
    "    \n",
    "#     for OutChannel in range(OutChannels):\n",
    "#         for i in range(OutChannels):\n",
    "#             for Kernel in range(KernelSize):\n",
    "#                 for InChannel in range(InChannels):\n",
    "#                     W[OutChannel, InChannel, Kernel] += x[i+Kernel, InChannel]\n",
    "#     return W\n",
    "\n",
    "print(calculate_kernel_grad(x, y, kernel, bias))\n",
    "# np.array([[[2.0, 1.0], \n",
    "#            [1.0, 1.0]], \n",
    "\n",
    "#           [[2.0, 1.0], \n",
    "#            [1.0, 1.0]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2579976950685653, 0.029957050945287222, 0.18958928880952108]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[0.5031766517322117, 0.30744410216949514], [0.04690208449415345, 0.322727131626243], [0.1388690574185909, 0.48576543724022325], [0.5260018011862109, 0.5859221562109312], [0.9194272143904142, 0.3887293155713266], [0.26873714217871125, 0.9546207791313607], [0.8974007607375208, 0.5713329992292489], [0.378989716528242, 0.49787928388753266]]\n",
    "\n",
    "[[1.5157583762374225, 0.9460413662192456, 0.9802340338281511], [1.5728362445918327, 0.996409724139607, 1.2530013664472253], [1.9068174476481374, 1.430592927945995, 1.6704630594015581], [2.189768979209843, 2.3149543871163503, 2.1601629609824995], [2.8353457102707083, 1.7422359297539565, 1.816707087141475], [2.0532913525958474, 1.9924093441385802, 2.3069493556139014]]\n",
    "\n",
    "[[[0.8077620147648772, 0.006392942850116379, 0.6080212915877307], [0.6288229869798402, 0.6410664904844843, 0.75419330562945]], [[0.5355186530459589, 0.9211024178840701, 0.27725553497982014], [0.4507098181629161, 0.081570594016668, 0.8234980185346139]], [[0.0325944131753374, 0.7744753133142763, 0.05946983249285043], [0.7059580971549311, 0.7969953841197822, 0.5257810951530107]]]\n",
    "\n",
    "[0.2579976950685653, 0.029957050945287222, 0.18958928880952108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (8, 2)\n",
      "[[0.50317665 0.3074441 ]\n",
      " [0.04690208 0.32272713]\n",
      " [0.13886906 0.48576544]\n",
      " [0.5260018  0.58592216]\n",
      " [0.91942721 0.38872932]\n",
      " [0.26873714 0.95462078]\n",
      " [0.89740076 0.571333  ]\n",
      " [0.37898972 0.49787928]]\n",
      "k (3, 2, 3)\n",
      "[[[0.80776201 0.00639294 0.60802129]\n",
      "  [0.62882299 0.64106649 0.75419331]]\n",
      "\n",
      " [[0.53551865 0.92110242 0.27725553]\n",
      "  [0.45070982 0.08157059 0.82349802]]\n",
      "\n",
      " [[0.03259441 0.77447531 0.05946983]\n",
      "  [0.7059581  0.79699538 0.5257811 ]]]\n",
      "y (6, 3)\n",
      "[[1.51575838 0.94604137 0.98023403]\n",
      " [1.57283624 0.99640972 1.25300137]\n",
      " [1.90681745 1.43059293 1.67046306]\n",
      " [2.18976898 2.31495439 2.16016296]\n",
      " [2.83534571 1.74223593 1.81670709]\n",
      " [2.05329135 1.99240934 2.30694936]]\n",
      "b (3,)\n",
      "31.683979653282336\n",
      "[[1.37587508 1.7854909 ]\n",
      " [3.07784576 3.30512337]\n",
      " [4.02259241 5.40859579]\n",
      " [4.02259241 5.40859579]\n",
      " [4.02259241 5.40859579]\n",
      " [4.02259241 5.40859579]\n",
      " [2.64671733 3.62310489]\n",
      " [0.94474666 2.10347242]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[0.5031766517322117, 0.30744410216949514], [0.04690208449415345, 0.322727131626243], [0.1388690574185909, 0.48576543724022325], [0.5260018011862109, 0.5859221562109312], [0.9194272143904142, 0.3887293155713266], [0.26873714217871125, 0.9546207791313607], [0.8974007607375208, 0.5713329992292489], [0.378989716528242, 0.49787928388753266]])\n",
    "y = np.array([[1.5157583762374225, 0.9460413662192456, 0.9802340338281511], [1.5728362445918327, 0.996409724139607, 1.2530013664472253], [1.9068174476481374, 1.430592927945995, 1.6704630594015581], [2.189768979209843, 2.3149543871163503, 2.1601629609824995], [2.8353457102707083, 1.7422359297539565, 1.816707087141475], [2.0532913525958474, 1.9924093441385802, 2.3069493556139014]])\n",
    "kernel = np.array([[[0.8077620147648772, 0.006392942850116379, 0.6080212915877307], [0.6288229869798402, 0.6410664904844843, 0.75419330562945]], [[0.5355186530459589, 0.9211024178840701, 0.27725553497982014], [0.4507098181629161, 0.081570594016668, 0.8234980185346139]], [[0.0325944131753374, 0.7744753133142763, 0.05946983249285043], [0.7059580971549311, 0.7969953841197822, 0.5257810951530107]]])\n",
    "bias = np.array([0.2579976950685653, 0.029957050945287222, 0.18958928880952108])\n",
    "\n",
    "print('x', data.shape)\n",
    "print(data)\n",
    "print('k', kernel.shape)\n",
    "print(kernel)\n",
    "print('y', y.shape)\n",
    "print(y)\n",
    "print('b', bias.shape)\n",
    "\n",
    "print(y.sum())\n",
    "\n",
    "def calculate_kernel_grad(x, y, kernel, bias):\n",
    "\n",
    "#     res = np.zeros(kernel.shape)\n",
    "#     for n in range(kernel.shape[0]):\n",
    "#         for i in range(len(data)-kernel.shape[2]+1):\n",
    "#             for j in range(kernel.shape[2]):\n",
    "#                 for c in range(kernel.shape[1]):\n",
    "#                      res[n,c,j] += data[i+j, c]\n",
    "#     return res    \n",
    "\n",
    "    res = np.zeros(data.shape)\n",
    "    for n in range(kernel.shape[0]):\n",
    "        for i in range(len(data)-kernel.shape[2]+1):\n",
    "            for j in range(kernel.shape[2]):\n",
    "                for c in range(kernel.shape[1]):\n",
    "                     res[i+j, c] += kernel[n, c, j]\n",
    "    return res  \n",
    "\n",
    "print(calculate_kernel_grad(x, y, kernel, bias))\n",
    "# np.array([[[2.0, 1.0], \n",
    "#            [1.0, 1.0]], \n",
    "\n",
    "#           [[2.0, 1.0], \n",
    "#            [1.0, 1.0]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "layers = list([[9, 9, 3],[2, 3, 4]])\n",
    "print(layers)\n",
    "def calculate_receptive_field(layers):\n",
    "    rfs = 0\n",
    "    layers[0][0] + (layers[0][1] - 1) * layers[0][2]\n",
    "    return rfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
